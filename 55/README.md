# LLM 파인튜닝 1-DAY 워크숍

> [github](https://github.com/daje0601/AI_workshop)

- 2025-10-19

## 내용 정리

제조업에서 고장내용을 통해 고장부품, 불량유형, 조치내용 데이터를 추출한 사례

- 자연어로 작성된 수술 확인서에서 관혈 등의 데이터를 추출할 수 있을 것

복잡한 문제의 경우 문제를 분리해서 적용할 수 있음

- 데이터 생성 → 검증 → …
- OpenAI 로 데이터를 만들고 → 검증 → …

학습을 해줄거니까 system prompt 를 안넣어도 괜찮을까?

> 학습을 하더라도 지시사항을 포함해서 넣어주는 것이 좋다.

full fine tuning vs LoRA

- full fine tuning: 전체를 학습
- LoRA: 일부만 학습
- full 이 항상 좋은 것은 아님. LoRA 가 더 좋은 경우도 많음.

LoRA 설정

- 아래의 LoRA 설정을 바꾸는 것이 학습에 영향을 크게 주지는 않음.
- 차라리 데이터를 더 잘 만드는 것이 좋다.
- 모델마다 최적화된 값이 다를 수는 있음

모델을 평가하는 방법

- 기존의 머신러닝 평가에서 사용하는 메트릭과 같음
- 요약과 같은 문제에서도 사용하는 평가방법도 있음
- 어쨋든 특정 문제에 필요한 메트릭들이 있을것.

멀티턴의 경우 모든 메시지를 다 넣기보다는 시스템 프롬프트는 유지하면서 최대 3(k)정도만 유지하는 등으로 컨텍스트 크기를 조절해볼 수 있다.

멀티 쿼리

- 메시지에 두 가지 질문이 있는 경우
- 멀티쿼리가 지원되는 모델이 있음

오타 등으로 쿼리를 제대로 수행하지 못 할 경우

- 오타를 포함해서 학습해볼 수 있다
- 오타를 잘 임베딩할 수 있는 모델을 사용해볼 수 있다

### 질문

입력 데이터도 메모리를 먹을거고, 추론 데이터도 메모리를 먹을 것 같은데 그거를 고려해서 vram 을 어느정도로 세팅해야 할까?

- 일단은 메모리를 고려하여 입력받을 수 있는 토큰량을 설정할 수 있는데 이 설정을 활용할 수 있음

문제를 작은 문제들로 나눠서 각각 slm을 사용하는 경우가 많은것같은데 slm 이 어느정도 문제까지 해결 가능할까?

- 실험이 필요함
